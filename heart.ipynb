{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d00b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "heart_df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca869512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display first 5 rows\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ec937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dataset summary\n",
    "heart_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dataset statistics\n",
    "heart_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8802432",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0af47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51141023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking duplicate values\n",
    "heart_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3316dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for unique values \n",
    "heart_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying column names\n",
    "heart_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying columns with object data type\n",
    "cat_col = heart_df.select_dtypes(include='object').columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35510e",
   "metadata": {},
   "source": [
    "converting categorical variables to numeric\n",
    "1. sex :m=0, f = 1\n",
    "2. ChestPainType:ATA=0, NAP=1, ASY=2, TA=3\n",
    "3. RestingECG:Normal=0, ST=1, LVH=2\n",
    "4. ExcersiceAngina: N=0, Y=1\n",
    "5. STSlope: UP=0, Flat=1, Down=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical variables to numeric\n",
    "for col in cat_col:\n",
    "    print(col)\n",
    "    print((heart_df[col].unique()),list(range(heart_df[col].nunique())))\n",
    "    heart_df[col].replace((heart_df[col].unique()), range(heart_df[col].nunique()), inplace=True)\n",
    "    print('*'*90)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00343ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df['Cholesterol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02465942",
   "metadata": {},
   "source": [
    "Imputing the 0 values in cholestrol column with KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df['Cholesterol'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "after_impute = imputer.fit_transform(heart_df)\n",
    "heart_df = pd.DataFrame(after_impute, columns=heart_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2da0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df['Cholesterol'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in heart_df['Cholesterol']:\n",
    "    if i == 0:\n",
    "        count += 1\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9af1a",
   "metadata": {},
   "source": [
    "Doing the same for Resting Blood Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df['RestingBP'][heart_df['RestingBP']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values in 'RestingBP' using KNNImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "heart_df = heart_df.copy()\n",
    "heart_df['RestingBP'] = heart_df['RestingBP'].replace(0, np.nan)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "heart_df = pd.DataFrame(imputer.fit_transform(heart_df), columns=heart_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df['RestingBP'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df['RestingBP'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f80f3b",
   "metadata": {},
   "source": [
    "change column type to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6dca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column type to int\n",
    "withoutOldPeak=heart_df.columns\n",
    "withoutOldPeak = withoutOldPeak.drop('Oldpeak')\n",
    "heart_df[withoutOldPeak] = heart_df[withoutOldPeak].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3dc40b",
   "metadata": {},
   "source": [
    "Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714da1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.corr()['HeartDisease'][:-1].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc492b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(heart_df.corr()['HeartDisease'][:-1].sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d253d2",
   "metadata": {},
   "source": [
    "Age and heart disease distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.sunburst(heart_df, path=['HeartDisease','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(heart_df, x='Age', color='HeartDisease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of heart disease data distribution\n",
    "px.pie(heart_df, names='HeartDisease', title='Heart Disease Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1efc764",
   "metadata": {},
   "source": [
    "sex vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d57549",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(heart_df, x='Sex', color='HeartDisease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a97be",
   "metadata": {},
   "source": [
    "Chestpaintype vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514752e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(heart_df, x='ChestPainType', color='HeartDisease')\n",
    "#chestpaintype: ATA=0, NAP=1, ASY=2, TA=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882cecc",
   "metadata": {},
   "source": [
    "RestingBP vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a60c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.sunburst(heart_df, path=['HeartDisease', 'RestingBP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52219bd2",
   "metadata": {},
   "source": [
    "FastingBS vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(heart_df, x='FastingBS', color='HeartDisease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecf214",
   "metadata": {},
   "source": [
    "MAXHR vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.sunburst(heart_df, path=['HeartDisease', 'MaxHR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ae8fb",
   "metadata": {},
   "source": [
    "OldPeak vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(heart_df, y='Oldpeak', color='HeartDisease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e4543",
   "metadata": {},
   "source": [
    "ST Slope vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(heart_df, x='ST_Slope', color='HeartDisease')\n",
    "# ST_Slope: down=0, Flat=1, up=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4489934",
   "metadata": {},
   "source": [
    "ExcersiseAnginia vs HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f02e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(heart_df, x='ExerciseAngina', color='HeartDisease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b369d30",
   "metadata": {},
   "source": [
    "Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656503a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    heart_df.drop('HeartDisease', axis=1),\n",
    "    heart_df['HeartDisease'],\n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=heart_df['HeartDisease']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe01abc",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling the data (important for some solvers)\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Defining solvers with their optimal settings\n",
    "solvers = {\n",
    "    'lbfgs': {'max_iter': 1000},\n",
    "    'liblinear': {'max_iter': 1000},\n",
    "    'sag': {'max_iter': 10000},      \n",
    "    'saga': {'max_iter': 10000},    \n",
    "    'newton-cg': {'max_iter': 1000},\n",
    "    'newton-cholesky': {'max_iter': 1000}\n",
    "}\n",
    "# Testing solvers with proper settings\n",
    "best_score = 0\n",
    "best_solver = None\n",
    "\n",
    "for solver, params in solvers.items():\n",
    "    try:\n",
    "        lr = LogisticRegression(solver=solver, **params)\n",
    "        lr.fit(x_train_scaled, y_train)\n",
    "        score = lr.score(x_test_scaled, y_test)\n",
    "        \n",
    "        print(f\"Solver: {solver:<15} Accuracy: {score:.4f}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_solver = solver\n",
    "    except Exception as e:\n",
    "        print(f\"Solver {solver} failed: {str(e)}\")\n",
    "\n",
    "# Final model with best solver\n",
    "if best_solver:\n",
    "    lr = LogisticRegression(solver=best_solver, \n",
    "                          max_iter=solvers[best_solver]['max_iter'])\n",
    "    lr.fit(x_train_scaled, y_train)\n",
    "    y_pred = lr.predict(x_test_scaled)\n",
    "    print(f'\\nBest solver: {best_solver}')\n",
    "    print(f'Final accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
    "else:\n",
    "    print(\"No suitable solver found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c633ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding pickle module\n",
    "import pickle\n",
    "file= open('logistic_regression_model.pkl', 'wb')\n",
    "pickle.dump(lr, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9b901",
   "metadata": {},
   "source": [
    "Performance matrics for logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics for Logistic Regression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "print('Logistic Regression Performance:')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1 Score:', f1_score(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a9c6d",
   "metadata": {},
   "source": [
    "Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "kernels = {'linear':0, 'poly':0, 'rbf':0, 'sigmoid':0}\n",
    "best = ''\n",
    "for i in kernels:\n",
    "    svm = SVC(kernel=i)\n",
    "    svm.fit(x_train, y_train)\n",
    "    yhat = svm.predict(x_test)\n",
    "    kernels[i] = f1_score(y_test, yhat, average='weighted')\n",
    "    if kernels[i]== max(kernels.values()):\n",
    "        best = i\n",
    "  \n",
    "svm = SVC(kernel=best)\n",
    "svm.fit(x_train, y_train)\n",
    "svm_pred = svm.predict(x_test)\n",
    "print(f'svm f1_score kernel=({best}) : {f1_score(y_test, svm_pred, average=\"weighted\"):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9febdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding pickle file\n",
    "import pickle\n",
    "file= open('svm_model.pkl', 'wb')\n",
    "pickle.dump(svm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5097593",
   "metadata": {},
   "source": [
    "Performance metrics for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f201a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics for SVM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "print('SVM Performance:')\n",
    "print('Accuracy:', accuracy_score(y_test, svm_pred))\n",
    "print('Precision:', precision_score(y_test, svm_pred))\n",
    "print('Recall:', recall_score(y_test, svm_pred))\n",
    "print('F1 Score:', f1_score(y_test, svm_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaab027",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f70acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dtree= DecisionTreeClassifier(class_weight='balanced')\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'random_state': [0, 42]\n",
    "} \n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)  \n",
    "ctree=DecisionTreeClassifier(**grid_search.best_params_, class_weight='balanced')\n",
    "ctree.fit(x_train, y_train)\n",
    "dtc_pred = ctree.predict(x_test)\n",
    "print(f\"Decision Tree's accuracy\", accuracy_score(y_test, dtc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8460dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding pickle module\n",
    "import pickle\n",
    "file= open('decision_tree_model.pkl', 'wb')\n",
    "pickle.dump(ctree, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f569c",
   "metadata": {},
   "source": [
    "Performance metrics for Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a872e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics for Decision Tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "print('Decision Tree Performance:')\n",
    "print('Accuracy:', accuracy_score(y_test, dtc_pred))\n",
    "print('Precision:', precision_score(y_test, dtc_pred))\n",
    "print('Recall:', recall_score(y_test, dtc_pred))\n",
    "print('F1 Score:', f1_score(y_test, dtc_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, dtc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b07433",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb688b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Corrected parameter grid (removed invalid 'none' from max_features)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 500],\n",
    "    'max_depth': [3, 6, 9, 19],\n",
    "    'max_features': ['sqrt', 'log2'],  # Removed 'none'\n",
    "    'max_leaf_nodes': [3, 6, 9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rfc, param_grid)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "rfctree = RandomForestClassifier(**grid_search.best_params_)\n",
    "rfctree.fit(x_train, y_train)\n",
    "rfc_pred = rfctree.predict(x_test)\n",
    "\n",
    "print(f\"Random Forest's accuracy: {accuracy_score(y_test, rfc_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding pickle module\n",
    "import pickle\n",
    "file= open('random_forest.pkl', 'wb')\n",
    "pickle.dump(rfctree, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f4448",
   "metadata": {},
   "source": [
    "Performance metrics for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics for Random Forest\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "print('Random Forest Performance:')\n",
    "print('Accuracy:', accuracy_score(y_test, rfc_pred))\n",
    "print('Precision:', precision_score(y_test, rfc_pred))\n",
    "print('Recall:', recall_score(y_test, rfc_pred))\n",
    "print('F1 Score:', f1_score(y_test, rfc_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy of logistic regression model\n",
    "print(\"Training accuracy:\", lr.score(x_train_scaled, y_train))\n",
    "print(\"Test accuracy:\", lr.score(x_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28f880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
